{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compound2unicode(text):\n",
    "  #https://gist.github.com/redphx/9320735`\n",
    "  text = text.replace(\"\\u0065\\u0309\", \"\\u1EBB\")    # ẻ\n",
    "  text = text.replace(\"\\u0065\\u0301\", \"\\u00E9\")    # é\n",
    "  text = text.replace(\"\\u0065\\u0300\", \"\\u00E8\")    # è\n",
    "  text = text.replace(\"\\u0065\\u0323\", \"\\u1EB9\")    # ẹ\n",
    "  text = text.replace(\"\\u0065\\u0303\", \"\\u1EBD\")    # ẽ\n",
    "  text = text.replace(\"\\u00EA\\u0309\", \"\\u1EC3\")    # ể\n",
    "  text = text.replace(\"\\u00EA\\u0301\", \"\\u1EBF\")    # ế\n",
    "  text = text.replace(\"\\u00EA\\u0300\", \"\\u1EC1\")    # ề\n",
    "  text = text.replace(\"\\u00EA\\u0323\", \"\\u1EC7\")    # ệ\n",
    "  text = text.replace(\"\\u00EA\\u0303\", \"\\u1EC5\")    # ễ\n",
    "  text = text.replace(\"\\u0079\\u0309\", \"\\u1EF7\")    # ỷ\n",
    "  text = text.replace(\"\\u0079\\u0301\", \"\\u00FD\")    # ý\n",
    "  text = text.replace(\"\\u0079\\u0300\", \"\\u1EF3\")    # ỳ\n",
    "  text = text.replace(\"\\u0079\\u0323\", \"\\u1EF5\")    # ỵ\n",
    "  text = text.replace(\"\\u0079\\u0303\", \"\\u1EF9\")    # ỹ\n",
    "  text = text.replace(\"\\u0075\\u0309\", \"\\u1EE7\")    # ủ\n",
    "  text = text.replace(\"\\u0075\\u0301\", \"\\u00FA\")    # ú\n",
    "  text = text.replace(\"\\u0075\\u0300\", \"\\u00F9\")    # ù\n",
    "  text = text.replace(\"\\u0075\\u0323\", \"\\u1EE5\")    # ụ\n",
    "  text = text.replace(\"\\u0075\\u0303\", \"\\u0169\")    # ũ\n",
    "  text = text.replace(\"\\u01B0\\u0309\", \"\\u1EED\")    # ử\n",
    "  text = text.replace(\"\\u01B0\\u0301\", \"\\u1EE9\")    # ứ\n",
    "  text = text.replace(\"\\u01B0\\u0300\", \"\\u1EEB\")    # ừ\n",
    "  text = text.replace(\"\\u01B0\\u0323\", \"\\u1EF1\")    # ự\n",
    "  text = text.replace(\"\\u01B0\\u0303\", \"\\u1EEF\")    # ữ\n",
    "  text = text.replace(\"\\u0069\\u0309\", \"\\u1EC9\")    # ỉ\n",
    "  text = text.replace(\"\\u0069\\u0301\", \"\\u00ED\")    # í\n",
    "  text = text.replace(\"\\u0069\\u0300\", \"\\u00EC\")    # ì\n",
    "  text = text.replace(\"\\u0069\\u0323\", \"\\u1ECB\")    # ị\n",
    "  text = text.replace(\"\\u0069\\u0303\", \"\\u0129\")    # ĩ\n",
    "  text = text.replace(\"\\u006F\\u0309\", \"\\u1ECF\")    # ỏ\n",
    "  text = text.replace(\"\\u006F\\u0301\", \"\\u00F3\")    # ó\n",
    "  text = text.replace(\"\\u006F\\u0300\", \"\\u00F2\")    # ò\n",
    "  text = text.replace(\"\\u006F\\u0323\", \"\\u1ECD\")    # ọ\n",
    "  text = text.replace(\"\\u006F\\u0303\", \"\\u00F5\")    # õ\n",
    "  text = text.replace(\"\\u01A1\\u0309\", \"\\u1EDF\")    # ở\n",
    "  text = text.replace(\"\\u01A1\\u0301\", \"\\u1EDB\")    # ớ\n",
    "  text = text.replace(\"\\u01A1\\u0300\", \"\\u1EDD\")    # ờ\n",
    "  text = text.replace(\"\\u01A1\\u0323\", \"\\u1EE3\")    # ợ\n",
    "  text = text.replace(\"\\u01A1\\u0303\", \"\\u1EE1\")    # ỡ\n",
    "  text = text.replace(\"\\u00F4\\u0309\", \"\\u1ED5\")    # ổ\n",
    "  text = text.replace(\"\\u00F4\\u0301\", \"\\u1ED1\")    # ố\n",
    "  text = text.replace(\"\\u00F4\\u0300\", \"\\u1ED3\")    # ồ\n",
    "  text = text.replace(\"\\u00F4\\u0323\", \"\\u1ED9\")    # ộ\n",
    "  text = text.replace(\"\\u00F4\\u0303\", \"\\u1ED7\")    # ỗ\n",
    "  text = text.replace(\"\\u0061\\u0309\", \"\\u1EA3\")    # ả\n",
    "  text = text.replace(\"\\u0061\\u0301\", \"\\u00E1\")    # á\n",
    "  text = text.replace(\"\\u0061\\u0300\", \"\\u00E0\")    # à\n",
    "  text = text.replace(\"\\u0061\\u0323\", \"\\u1EA1\")    # ạ\n",
    "  text = text.replace(\"\\u0061\\u0303\", \"\\u00E3\")    # ã\n",
    "  text = text.replace(\"\\u0103\\u0309\", \"\\u1EB3\")    # ẳ\n",
    "  text = text.replace(\"\\u0103\\u0301\", \"\\u1EAF\")    # ắ\n",
    "  text = text.replace(\"\\u0103\\u0300\", \"\\u1EB1\")    # ằ\n",
    "  text = text.replace(\"\\u0103\\u0323\", \"\\u1EB7\")    # ặ\n",
    "  text = text.replace(\"\\u0103\\u0303\", \"\\u1EB5\")    # ẵ\n",
    "  text = text.replace(\"\\u00E2\\u0309\", \"\\u1EA9\")    # ẩ\n",
    "  text = text.replace(\"\\u00E2\\u0301\", \"\\u1EA5\")    # ấ\n",
    "  text = text.replace(\"\\u00E2\\u0300\", \"\\u1EA7\")    # ầ\n",
    "  text = text.replace(\"\\u00E2\\u0323\", \"\\u1EAD\")    # ậ\n",
    "  text = text.replace(\"\\u00E2\\u0303\", \"\\u1EAB\")    # ẫ\n",
    "  text = text.replace(\"\\u0045\\u0309\", \"\\u1EBA\")    # Ẻ\n",
    "  text = text.replace(\"\\u0045\\u0301\", \"\\u00C9\")    # É\n",
    "  text = text.replace(\"\\u0045\\u0300\", \"\\u00C8\")    # È\n",
    "  text = text.replace(\"\\u0045\\u0323\", \"\\u1EB8\")    # Ẹ\n",
    "  text = text.replace(\"\\u0045\\u0303\", \"\\u1EBC\")    # Ẽ\n",
    "  text = text.replace(\"\\u00CA\\u0309\", \"\\u1EC2\")    # Ể\n",
    "  text = text.replace(\"\\u00CA\\u0301\", \"\\u1EBE\")    # Ế\n",
    "  text = text.replace(\"\\u00CA\\u0300\", \"\\u1EC0\")    # Ề\n",
    "  text = text.replace(\"\\u00CA\\u0323\", \"\\u1EC6\")    # Ệ\n",
    "  text = text.replace(\"\\u00CA\\u0303\", \"\\u1EC4\")    # Ễ\n",
    "  text = text.replace(\"\\u0059\\u0309\", \"\\u1EF6\")    # Ỷ\n",
    "  text = text.replace(\"\\u0059\\u0301\", \"\\u00DD\")    # Ý\n",
    "  text = text.replace(\"\\u0059\\u0300\", \"\\u1EF2\")    # Ỳ\n",
    "  text = text.replace(\"\\u0059\\u0323\", \"\\u1EF4\")    # Ỵ\n",
    "  text = text.replace(\"\\u0059\\u0303\", \"\\u1EF8\")    # Ỹ\n",
    "  text = text.replace(\"\\u0055\\u0309\", \"\\u1EE6\")    # Ủ\n",
    "  text = text.replace(\"\\u0055\\u0301\", \"\\u00DA\")    # Ú\n",
    "  text = text.replace(\"\\u0055\\u0300\", \"\\u00D9\")    # Ù\n",
    "  text = text.replace(\"\\u0055\\u0323\", \"\\u1EE4\")    # Ụ\n",
    "  text = text.replace(\"\\u0055\\u0303\", \"\\u0168\")    # Ũ\n",
    "  text = text.replace(\"\\u01AF\\u0309\", \"\\u1EEC\")    # Ử\n",
    "  text = text.replace(\"\\u01AF\\u0301\", \"\\u1EE8\")    # Ứ\n",
    "  text = text.replace(\"\\u01AF\\u0300\", \"\\u1EEA\")    # Ừ\n",
    "  text = text.replace(\"\\u01AF\\u0323\", \"\\u1EF0\")    # Ự\n",
    "  text = text.replace(\"\\u01AF\\u0303\", \"\\u1EEE\")    # Ữ\n",
    "  text = text.replace(\"\\u0049\\u0309\", \"\\u1EC8\")    # Ỉ\n",
    "  text = text.replace(\"\\u0049\\u0301\", \"\\u00CD\")    # Í\n",
    "  text = text.replace(\"\\u0049\\u0300\", \"\\u00CC\")    # Ì\n",
    "  text = text.replace(\"\\u0049\\u0323\", \"\\u1ECA\")    # Ị\n",
    "  text = text.replace(\"\\u0049\\u0303\", \"\\u0128\")    # Ĩ\n",
    "  text = text.replace(\"\\u004F\\u0309\", \"\\u1ECE\")    # Ỏ\n",
    "  text = text.replace(\"\\u004F\\u0301\", \"\\u00D3\")    # Ó\n",
    "  text = text.replace(\"\\u004F\\u0300\", \"\\u00D2\")    # Ò\n",
    "  text = text.replace(\"\\u004F\\u0323\", \"\\u1ECC\")    # Ọ\n",
    "  text = text.replace(\"\\u004F\\u0303\", \"\\u00D5\")    # Õ\n",
    "  text = text.replace(\"\\u01A0\\u0309\", \"\\u1EDE\")    # Ở\n",
    "  text = text.replace(\"\\u01A0\\u0301\", \"\\u1EDA\")    # Ớ\n",
    "  text = text.replace(\"\\u01A0\\u0300\", \"\\u1EDC\")    # Ờ\n",
    "  text = text.replace(\"\\u01A0\\u0323\", \"\\u1EE2\")    # Ợ\n",
    "  text = text.replace(\"\\u01A0\\u0303\", \"\\u1EE0\")    # Ỡ\n",
    "  text = text.replace(\"\\u00D4\\u0309\", \"\\u1ED4\")    # Ổ\n",
    "  text = text.replace(\"\\u00D4\\u0301\", \"\\u1ED0\")    # Ố\n",
    "  text = text.replace(\"\\u00D4\\u0300\", \"\\u1ED2\")    # Ồ\n",
    "  text = text.replace(\"\\u00D4\\u0323\", \"\\u1ED8\")    # Ộ\n",
    "  text = text.replace(\"\\u00D4\\u0303\", \"\\u1ED6\")    # Ỗ\n",
    "  text = text.replace(\"\\u0041\\u0309\", \"\\u1EA2\")    # Ả\n",
    "  text = text.replace(\"\\u0041\\u0301\", \"\\u00C1\")    # Á\n",
    "  text = text.replace(\"\\u0041\\u0300\", \"\\u00C0\")    # À\n",
    "  text = text.replace(\"\\u0041\\u0323\", \"\\u1EA0\")    # Ạ\n",
    "  text = text.replace(\"\\u0041\\u0303\", \"\\u00C3\")    # Ã\n",
    "  text = text.replace(\"\\u0102\\u0309\", \"\\u1EB2\")    # Ẳ\n",
    "  text = text.replace(\"\\u0102\\u0301\", \"\\u1EAE\")    # Ắ\n",
    "  text = text.replace(\"\\u0102\\u0300\", \"\\u1EB0\")    # Ằ\n",
    "  text = text.replace(\"\\u0102\\u0323\", \"\\u1EB6\")    # Ặ\n",
    "  text = text.replace(\"\\u0102\\u0303\", \"\\u1EB4\")    # Ẵ\n",
    "  text = text.replace(\"\\u00C2\\u0309\", \"\\u1EA8\")    # Ẩ\n",
    "  text = text.replace(\"\\u00C2\\u0301\", \"\\u1EA4\")    # Ấ\n",
    "  text = text.replace(\"\\u00C2\\u0300\", \"\\u1EA6\")    # Ầ\n",
    "  text = text.replace(\"\\u00C2\\u0323\", \"\\u1EAC\")    # Ậ\n",
    "  text = text.replace(\"\\u00C2\\u0303\", \"\\u1EAA\")    # Ẫ\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['name_activity', 'type_activity', 'holder', 'time', 'name_place', 'address', 'reward', 'contact', 'register', 'works', 'joiner'])\n",
      "------------------------works\n",
      "giúp đỡ những gia đình khó khăn , sửa chữa lại hệ thống điện mất an toàn\n",
      "giúp đỡ đội\n",
      "giúp đỡ cho các bạn sinh viên có hoàn cảnh khó khăn\n",
      "khuyên góp quần áo cũ và gạo để giúp đỡ bà con\n",
      "giúp đỡ nhóm vận chuyển quà\n",
      "san sẻ , giúp đỡ những người dân đồng bào vùng biên giới\n",
      "hỗ trợ những người dân nghèo , khó khăn , giúp đỡ cho các em học sinh là đồng bào dân tộc thiểu số\n",
      "giúp đỡ các gia đình có hoàn cảnh khó khăn\n",
      "giúp đỡ những người gặp hoàn cảnh khó khăn\n",
      "hỗ trợ bán bí giúp đỡ bà con nông dân ea kar đắk lắk\n",
      "giúp đỡ , chia sẻ , đùm bọc bà con\n"
     ]
    }
   ],
   "source": [
    "with open('real_dict_2000_new_only_delete_question_noti_new_and_space_newest.json','r') as dict_file:\n",
    "    real_dict = json.load(dict_file)\n",
    "    print(real_dict.keys())\n",
    "    list_holder = real_dict['holder']\n",
    "    list_name_place = real_dict['name_place']\n",
    "    list_name_activity = real_dict['name_activity']\n",
    "    list_joiner = real_dict['joiner']\n",
    "    list_type_activity = real_dict['type_activity']\n",
    "    list_reward = real_dict['reward']\n",
    "    list_works = real_dict['works']\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    print(\"------------------------works\")\n",
    "    for works in list_works:\n",
    "        if compound2unicode(\"giúp đỡ\") in compound2unicode(works):\n",
    "            print(works)\n",
    "            \n",
    "#     print(\"------------------------reward\")\n",
    "#     for reward in list_reward:\n",
    "#         if compound2unicode(\"của\") in compound2unicode(reward) and compound2unicode(\"nhà\") in compound2unicode(reward) and compound2unicode(\"trường\") in compound2unicode(reward):\n",
    "#             print(reward)\n",
    "            \n",
    "#     print(\"------------------------type activity\")\n",
    "#     for type_activity in list_type_activity:\n",
    "#         if compound2unicode(\"hỗ trợ\") in compound2unicode(type_activity):\n",
    "#             print(type_activity)\n",
    "            \n",
    "#     print(\"------------------------holder\")\n",
    "#     for holder in list_holder:\n",
    "#         if compound2unicode(\"hỗ trợ\") in compound2unicode(holder):\n",
    "#             print(holder)\n",
    "            \n",
    "#     for joiner in list_joiner:\n",
    "#         if \"tham dự\" in joiner:\n",
    "#             print(joiner)\n",
    "#         if name_activity.find(\"chương trình\") == 0:\n",
    "#             res.append(name_activity.replace(\"chương trình \",\"\"))\n",
    "#         else:\n",
    "#             res.append(name_activity)\n",
    "# #     print(res)\n",
    "#     real_dict['name_activity'] = res\n",
    "#     with open('real_dict_2000_new_only_delete_question_noti_new_and_space_newest.json', 'w+') as new_dict_file:\n",
    "#         json.dump(real_dict,new_dict_file,ensure_ascii=False)\n",
    "# print(list_holder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494\n"
     ]
    }
   ],
   "source": [
    "with open('temp_data/real_db_769.json','r') as db_file:\n",
    "    list_data = json.load(db_file)\n",
    "#     print(list_data)\n",
    "    res = list_data\n",
    "    for data in list_data:\n",
    "        check_not_match_holder = False\n",
    "#         if 'name_activity' not in list(data.keys()):\n",
    "#             break\n",
    "        for holder in data['holder']:\n",
    "            if holder not in list_holder:\n",
    "                check_not_match_holder = True\n",
    "                break\n",
    "        if check_not_match_holder == True:\n",
    "            res.remove(data)\n",
    "            \n",
    "    for data in list_data:\n",
    "        check_not_match_name_place = False\n",
    "#         if 'name_activity' not in list(data.keys()):\n",
    "#             break\n",
    "        for name_place in data['name_place']:\n",
    "            if name_place not in list_name_place:\n",
    "                check_not_match_name_place = True\n",
    "                break\n",
    "        if check_not_match_name_place == True:\n",
    "            res.remove(data)\n",
    "    \n",
    "    \n",
    "    print(len(res))\n",
    "    with open('temp_data/real_db_494.json','w+') as new_db_file:\n",
    "        json.dump(res,new_db_file,ensure_ascii=False)\n",
    "    \n",
    "                \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\d\\d\\d\n"
     ]
    }
   ],
   "source": [
    "with open('list_constants.json','r') as constants_file:\n",
    "    list_constants = json.load(constants_file)\n",
    "    list_pattern_time = list_constants['list_pattern_time']\n",
    "    for pattern in list_pattern_time:\n",
    "        if re.findall(pattern,'305') != []:\n",
    "            print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from temp_agent_action_gen import *\n",
    "from message_handler import *\n",
    "from agen_response_gen import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_entity(intent,input_sentence):\n",
    "    print(\"duongcc\")\n",
    "    normalized_input_sentence = compound2unicode(input_sentence)\n",
    "    normalized_input_sentence = delete_extra_word(normalized_input_sentence,list_extra_word)\n",
    "    \n",
    "    result_entity_dict={}\n",
    "    list_order_entity_name=map_intent_to_list_order_entity_name[intent]\n",
    "    print(normalized_input_sentence)\n",
    "    if 'time' in list_order_entity_name:\n",
    "        for pattern_time in list_pattern_time:\n",
    "            if re.findall(pattern_time,normalized_input_sentence)!=[]:\n",
    "                # print(\"pattern_time :{0}\".format(pattern_time))\n",
    "                if 'time' not in result_entity_dict:\n",
    "                    result_entity_dict['time'] = delete_last_space_list(re.findall(pattern_time,normalized_input_sentence))\n",
    "                else:\n",
    "                    result_entity_dict['time'].extend(delete_last_space_list(re.findall(pattern_time,normalized_input_sentence)))\n",
    "                \n",
    "                normalized_input_sentence = re.sub(pattern_time,' '.join(['✪']*(pattern_time.count(' ')+1)),normalized_input_sentence)\n",
    "        # if 'time' in result_entity_dict:\n",
    "        #     print(result_entity_dict['time'])\n",
    "    if 'reward' in list_order_entity_name:\n",
    "        for pattern_reward in list_pattern_reward:\n",
    "            if re.findall(pattern_reward,normalized_input_sentence)!=[]:\n",
    "                print(\"pattern_reward :{0}\".format(pattern_reward))\n",
    "                if 'reward' not in result_entity_dict:\n",
    "                    result_entity_dict['reward'] = delete_last_space_list(re.findall(pattern_reward,normalized_input_sentence))\n",
    "                else:\n",
    "                    result_entity_dict['reward'].extend(delete_last_space_list(re.findall(pattern_reward,normalized_input_sentence)))\n",
    "                \n",
    "                normalized_input_sentence = re.sub(pattern_reward,' '.join(['✪']*(pattern_reward.count(' ')+1)),normalized_input_sentence)\n",
    "        # if 'reward' in result_entity_dict:\n",
    "        #     print(result_entity_dict['reward'])\n",
    "    matching_threshold = 0.0\n",
    "    longest_common_length, end_common_index = None, None\n",
    "    \n",
    "    map_entity_name_to_threshold={}\n",
    "    for entity_name in list_order_entity_name:\n",
    "        if entity_name in ['time','address']:\n",
    "            map_entity_name_to_threshold[entity_name]=1\n",
    "        elif entity_name in ['name_activity','contact','joiner','holder','type_activity','name_place']:\n",
    "            map_entity_name_to_threshold[entity_name]=2\n",
    "        elif entity_name in ['works','reward']:\n",
    "            map_entity_name_to_threshold[entity_name]=2\n",
    "        elif entity_name in ['register']:\n",
    "            map_entity_name_to_threshold[entity_name]=3\n",
    "\n",
    "\n",
    "    ordered_real_dict = OrderedDict()\n",
    "    for entity_name in map_intent_to_list_order_entity_name[intent]:\n",
    "        ordered_real_dict[entity_name] = real_dict[entity_name]\n",
    "    for entity_name, list_entity in ordered_real_dict.items():\n",
    "        # print(entity_name)\n",
    "        list_entity = [entity.lower() for entity in list_entity]\n",
    "        # print(\"input sentence: {0}\".format(normalized_input_sentence))\n",
    "        if entity_name in [\"works\",\"register\",\"reward\"]:\n",
    "            matching_threshold = 0.15\n",
    "        elif entity_name == \"joiner\":\n",
    "            matching_threshold = 0.2\n",
    "        else:\n",
    "            matching_threshold = 0.5\n",
    "        print(\"000. sentence:{0}\".format(normalized_input_sentence))\n",
    "        catch_entity_threshold_loop = 0\n",
    "        while True:\n",
    "            if catch_entity_threshold_loop > 5:\n",
    "                break\n",
    "            list_dict_longest_common_entity = find_entity_longest_common(normalized_input_sentence,list_entity,entity_name)\n",
    "#             print(list_dict_longest_common_entity)\n",
    "                #     [{'longest_common_entity_index': 0,\n",
    "                #   'longest_common_length': 3,\n",
    "                #   'end_common_index': 9}]\n",
    "            \n",
    "\n",
    "            ##find the most match longest common match (calculate by length of token match in sentence \n",
    "                                                                #/ length of entity )\n",
    "                            ##{'greatest_match_entity_index':0,'longest_common_length':3,'end_common_index':9}\n",
    "            if list_dict_longest_common_entity == []:\n",
    "                break\n",
    "            if list_dict_longest_common_entity[0]['longest_common_length'] < map_entity_name_to_threshold[entity_name] :\n",
    "                break\n",
    "            \n",
    "            list_sentence_token = normalized_input_sentence.split(' ')\n",
    "#             print(\"list_sentence_token :{0}\".format(list_sentence_token))\n",
    "            greatest_entity_index=None\n",
    "            greatest_common_length = None\n",
    "            greatest_end_common_index = None\n",
    "            max_match_entity = 0.0\n",
    "#             print(\"common entity :{0}\".format(list_dict_longest_common_entity))\n",
    "            for dict_longest_common_entity in list_dict_longest_common_entity:\n",
    "#                 print(\"0. dict_longest_common_entity: {0}\".format(dict_longest_common_entity))\n",
    "\n",
    "#                     print(\"duong\")\n",
    "#                 print(\"0.1 entity: {0}\".format(list_entity[dict_longest_common_entity['longest_common_entity_index']]))\n",
    "                longest_common_entity_index = dict_longest_common_entity['longest_common_entity_index']\n",
    "                longest_common_length = dict_longest_common_entity['longest_common_length']\n",
    "                end_common_index = dict_longest_common_entity['end_common_index']\n",
    "                \n",
    "                list_sentence_token_match = list_sentence_token[end_common_index - longest_common_length+1:end_common_index+1]\n",
    "                if entity_name == \"type_activity\":\n",
    "                    if \"ban chỉ huy\" in normalized_input_sentence or \"ban tổ chức\" in normalized_input_sentence or \"bch\" in normalized_input_sentence or \"btc\" in normalized_input_sentence:\n",
    "                        continue\n",
    "                    #nếu chỉ là các câu inform 1 entity mà câu đó không phải là câu inform tên 1 hoạt động thì không cần xét\n",
    "                    if \"inform\" not in intent or \"name_activity\" in intent:\n",
    "                        list_name_activity = ordered_real_dict['name_activity']\n",
    "                        check_in_name = False\n",
    "                        for name_activity in list_name_activity:\n",
    "                            #nếu loại hoạt động nằm trọn trong bất kì 1 tên hoạt động \n",
    "                            # thì không lấy\n",
    "                            if  name_activity.find(' '.join(list_sentence_token_match)) > 0:\n",
    "                                check_in_name = True\n",
    "                                break\n",
    "                        if check_in_name == True:\n",
    "                            continue\n",
    "                \n",
    "                if entity_name == \"holder\":\n",
    "                    # nếu holder mà trước đó có từ chỉ nơi chốn : ở, tại => không là holder mà là  \n",
    "                    # name_place\n",
    "                    if end_common_index - longest_common_length >= 0:\n",
    "                        if list_sentence_token[end_common_index - longest_common_length] in [\"ở\",\"tại\",\"trước\",\"sau\",\"trong\"]:\n",
    "                            if 'name_place' in result_entity_dict:\n",
    "            #                     result_entity_dict[entity_name].append(list_entity[greatest_entity_index])\n",
    "                                result_entity_dict['name_place'].append(' '.join(list_sentence_token_match))\n",
    "                            else:\n",
    "            #                     result_entity_dict[entity_name] = [list_entity[greatest_entity_index]]\n",
    "                                result_entity_dict['name_place'] = [' '.join(list_sentence_token_match)]\n",
    "                            list_sentence_token[end_common_index - longest_common_length +1 :end_common_index +1] = [\"✪\"]*longest_common_length\n",
    "                            normalized_input_sentence = ' '.join(list_sentence_token)\n",
    "                            continue\n",
    "\n",
    "#                 print(\"2. list_sentence_token_match : {0}\".format(list_sentence_token_match))\n",
    "                list_temp_longest_entity_token = list_entity[longest_common_entity_index].split(' ')\n",
    "#                 print(\"3. list_temp_longest_entity_token : {0}\".format(list_temp_longest_entity_token))\n",
    "                if entity_name in [\"works\",\"register\",\"reward\"]:\n",
    "#                     print(\"list_temp_longest_entity_token :{0}\".format(list_temp_longest_entity_token))\n",
    "#                     print(\"list_sentence_token_match :{0}\".format(list_sentence_token_match))\n",
    "                    _,longest_common_length_entity,end_common_index_entity = lcs_length_ta(list_temp_longest_entity_token,list_sentence_token_match)\n",
    "                    list_entity_token_match = list_temp_longest_entity_token[end_common_index_entity - longest_common_length_entity +1 :end_common_index_entity +1]\n",
    "                    score = len(list_entity_token_match)/float(len(list_temp_longest_entity_token))\n",
    "#                     print(\"list_entity_token_match: {0}\".format(list_entity_token_match))\n",
    "#                     print(\"list_temp_longest_entity_token:{0}\".format(list_temp_longest_entity_token))\n",
    "#                     print(\"score :{0}\".format(score))\n",
    "                    \n",
    "                else:\n",
    "                    score = len(list_sentence_token_match)/float(len(list_temp_longest_entity_token))\n",
    "                if score > max_match_entity:\n",
    "#                     max_match_entity = len(list_sentence_token_match)/float(len(list_temp_longest_entity_token))\n",
    "                    max_match_entity = score\n",
    "                    greatest_entity_index = longest_common_entity_index\n",
    "                    greatest_common_length = longest_common_length\n",
    "                    greatest_end_common_index = end_common_index\n",
    "#             print(list_sentence_token)\n",
    "#             print(greatest_common_length)\n",
    "#             print(greatest_end_common_index)\n",
    "#             print(\"longest_common_length: {0}\".format(longest_common_length))\n",
    "#             print(\"end_common_index: {0}\".format(end_common_index))\n",
    "#             print(\"1. greatest_common_length : {0}\".format(greatest_common_length))\n",
    "            # print(max_match_entity)\n",
    "            # print(\"2. greatest entity : {0}\".format(list_entity[greatest_entity_index]))\n",
    "#             print(\"2.1 greatest_end_common_index: {0}\".format(greatest_end_common_index))\n",
    "#             print(\"3. sentence match: {0}\".format(list_sentence_token[greatest_end_common_index - greatest_common_length +1 :greatest_end_common_index +1]))\n",
    "            if greatest_common_length != None:\n",
    "                if greatest_common_length >= map_entity_name_to_threshold[entity_name] and max_match_entity > matching_threshold:\n",
    "                    # if entity_name in ['name_activity','type_activity']:\n",
    "                    #     result = list_entity[greatest_entity_index]\n",
    "                    # else:\n",
    "                    #     result = ' '.join(list_sentence_token[greatest_end_common_index - greatest_common_length +1 :greatest_end_common_index +1])\n",
    "                    \n",
    "                    result = ' '.join(list_sentence_token[greatest_end_common_index - greatest_common_length +1 :greatest_end_common_index +1])\n",
    "                    if entity_name in result_entity_dict:\n",
    "    #                     result_entity_dict[entity_name].append(list_entity[greatest_entity_index])\n",
    "                        result_entity_dict[entity_name].append(result)\n",
    "                    else:\n",
    "    #                     result_entity_dict[entity_name] = [list_entity[greatest_entity_index]]\n",
    "                        result_entity_dict[entity_name] = [result]\n",
    "    #                 list_sentence_token = list_sentence_token[:greatest_end_common_index - greatest_common_length + 1] + list_sentence_token[greatest_end_common_index +1 :]\n",
    "                    list_sentence_token[greatest_end_common_index - greatest_common_length +1 :greatest_end_common_index +1] = [\"✪\"]*greatest_common_length\n",
    "                    normalized_input_sentence = ' '.join(list_sentence_token)\n",
    "            catch_entity_threshold_loop = catch_entity_threshold_loop + 1\n",
    "            # print(\"output sentence: {0}\".format(normalized_input_sentence))\n",
    "    return result_entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✪ ✪ ✪ diễn ra hiến máu tình nguyện đợt ii ở hội trường lớn đh ngân hàng vậy\n",
      "{'intent': 'request', 'inform_slots': {'time': ['hội trường'], 'name_activity': ['hiến máu tình nguyện đợt ii'], 'holder': ['đh ngân hàng']}, 'request_slots': {'time': 'UNK'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CONSTANT_FILE_PATH = 'constants.json'\n",
    "with open(CONSTANT_FILE_PATH) as f:\n",
    "    constants = json.load(f)\n",
    "\n",
    "file_path_dict = constants['db_file_paths']\n",
    "DATABASE_FILE_PATH = file_path_dict['database']\n",
    "\n",
    "database= json.load(open(DATABASE_FILE_PATH,encoding='utf-8'))\n",
    "state_tracker = StateTracker(database, constants)\n",
    "dqn_agent = DQNAgent(state_tracker.get_state_size(), constants)\n",
    "#TEST\n",
    "if __name__ == '__main__':\n",
    "    print(process_message_to_user_request(\"khi nào thì diễn ra hiến máu tình nguyện đợt ii ở hội trường lớn đh ngân hàng vậy\",state_tracker))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\d\\d\\d?h \\d\\d\\d?h các buổi tối trong tuần \\( từ thứ \\d đến chủ nhật \\) , bắt đầu từ thứ \\d tuần này \\( \\d\\d?[/-]\\d\\d \\)\n",
      "\\d\\d\\d?h\\d?\\d?’ ngày \\d - \\d - \\d\\d\\d\\d \\( chủ nhật \\) \\d\\d?h\\d?\\d?’ ngày \\d\\d - \\d - \\d\\d\\d\\d \\( thứ \\d \\)\n",
      "từ \\d\\d?h đến \\d\\d\\d?h các ngày chủ nhật . \\( \\d\\d?[/-]\\d\\d ; \\d[/-]\\d\\d ; \\d\\d?[/-]\\d\\d ; \\d\\d?[/-]\\d\\d \\)\n",
      "chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? , từ \\d\\d?h\\d?\\d? sáng , dự kiến kết thúc lúc \\d\\d\\d?h\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? - \\d\\d\\d?h\\d?\\d? chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? và \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "từ ngày \\d\\d?[/-]\\d\\d đến \\d\\d?[/-] \\d\\d?[/-] \\d\\d\\d\\d \\( vào các ngày thứ \\d , chủ nhật hàng tuần \\)\n",
      "từ sáng thứ \\d , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? đến trưa chủ nhật , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "từ \\d\\d?h ngày \\d\\d?[/-]\\d \\d\\d\\d?h ngày \\d[/-]\\d\\d?[/-]\\d\\d\\d?\\d? . \\( thứ \\d & chủ nhật \\)\n",
      "thứ \\d & chủ nhật hằng tuần từ \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "từ \\d\\d\\d?h\\d?\\d? đến \\d\\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "từ \\d\\d?h\\d?\\d?’ đến \\d\\d?h\\d?\\d? , ngày \\d\\d tháng \\d\\d .* \\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d\\d?h\\d?\\d?’ – \\d\\d\\d?h\\d?\\d?’ ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d? đến \\d\\d\\d?h\\d?\\d? \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d? \\( nhằm ngày chủ nhật \\)\n",
      "từ \\d\\d?h\\d?\\d? - \\d\\d\\d?h\\d?\\d? . \\( mỗi sáng thứ \\d hoặc mỗi sáng chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d?’ \\d\\d\\d?h\\d?\\d?’ , ngày \\d[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d? \\d\\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "thứ \\d[/-]\\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "sáng chủ nhật tuần này , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? lúc \\d\\d?h\\d?\\d? sáng\n",
      "từ \\d\\dg\\d\\d đến \\d\\dg\\d\\d , ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d? - \\d\\d\\d?h\\d?\\d? chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? – \\d\\d\\d?h , ngày \\d\\d tháng \\d\\d .* \\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d? \\d\\d?h\\d?\\d? , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "lúc \\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( sáng chủ nhật \\)\n",
      "ngày mai chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? vào lúc \\d\\d\\d?h\\d?\\d?\n",
      "kết thúc vào \\d\\d?h sáng chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\)\n",
      "\\d : \\d\\d \\d\\d : \\d\\d , chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h - \\d\\d\\d?h\\d?\\d? , chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? đến \\d\\d\\d?h\\d?\\d? chủ nhật ngày \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "ngày mai , chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? đúng \\d\\d?h\\d?\\d?p\n",
      "chủ nhật đầu tiên của mỗi tháng , bắt đầu từ tháng \\d[/-]\\d\\d\\d?\\d?\n",
      "các ngày thứ \\d và chủ nhật từ ngày \\d\\d?[/-]\\d đến \\d\\d?[/-]\\d\\d  \n",
      "\\d\\d?h\\d?\\d? \\( sáng chủ nhật \\) ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\dg\\d\\d – \\d\\dg\\d\\d ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \n",
      "\\d\\dg\\d\\d \\d\\dg\\d\\d , chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chiều chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\) , \\d\\d\\d?h\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? - \\d\\d\\d?h ngày \\d\\d - \\d\\d - \\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d\\d?h\\d?\\d? \\d\\d\\d?h\\d?\\d? , ngày \\d\\d tháng \\d \\( chủ nhật \\)\n",
      "ngày \\d\\d - \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( thứ \\d , chủ nhật \\)\n",
      "\\d\\d\\d?h\\d?\\d?’ ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "bắt đầu từ \\d\\d\\d?h\\d?\\d? ngày \\d\\d.\\d\\d.\\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d giờ \\d\\d , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "từ sáng đến chiều ngày chủ nhật , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \n",
      "\\d\\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\) , lúc \\d\\d?h\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? sáng chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? phút chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "từ \\d\\d\\d?h\\d?\\d? , chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\dg\\d\\d ngày mai , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "thứ .* , chủ nhật này , ngày \\d\\d , \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? sáng chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\)\n",
      "\\d giờ \\d\\d , ngày \\d\\d tháng \\d\\d .* \\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d?h sáng hôm nay , chủ nhật ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d \\d\\d : \\d\\d , chủ nhật , ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\) .\n",
      " \\d\\d?h - \\d\\d\\d?h và \\d\\d\\d?h - \\d\\d\\d?h \\( trừ chủ nhật \\)\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật nhằm ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d? \n",
      "chủ nhật , \\d\\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? ngày chủ nhật , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? – \\d\\d\\d?h , chủ nhật , \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "thứ \\d , chủ nhật này , ngày \\d\\d , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\n",
      "\\d\\d \\d\\d : \\d\\d , chủ nhật , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chiều chủ nhật tuần sau \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\)\n",
      "thứ \\d hoặc chủ nhật \\( ngày \\d\\d?[/-]\\d và \\d\\d?[/-]\\d \\)\n",
      "từ \\d\\d?h \\d\\d\\d?h ngày chủ nhật \\d[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\dg\\d\\d - \\d\\dg\\d\\d chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? sáng chủ nhật ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? ngày chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\) \\d\\d?h\\d?\\d?\n",
      "\\d\\d\\d?h trưa chủ nhật ngày mai , \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật lúc \\d\\dg\\d\\d ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\dg\\d\\d ngày \\d\\d tháng \\d .* \\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d?h\\d?\\d? tối ngày thứ \\d tuần này tới sáng chủ nhật\n",
      "\\d\\d\\d?h , chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\dg\\d\\d , chủ nhật , ngày \\d\\d tháng \\d\\d .* \\d\\d\\d\\d\n",
      "\\d\\d?h\\d?\\d? chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h - \\d\\d\\d?h\\d?\\d? chủ nhật \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h sáng chủ nhật này , \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h sáng chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d? , chủ nhật ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật ngày \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d?h\\d?\\d?’ ngày \\d\\d - \\d - \\d\\d\\d\\d \\( chủ nhật \\)\n",
      "bắt đầu vào lúc \\d\\d\\d?h chủ nhật tuần này \\d[/-]\\d\\d\n",
      "chủ nhật tuần này , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật tuần này \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\)\n",
      "\\d\\d?h\\d?\\d? , chủ nhật ngày \\d tháng \\d .* \\d\\d\\d\\d\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật ngày \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật tuần này \\( ngày \\d\\d - \\d\\d - \\d\\d\\d\\d \\)\n",
      "vào lúc \\d\\d?h ngày \\d\\d.\\d.\\d\\d\\d\\d \\( chủ nhật \\)\n",
      "\\d\\dg chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "sáng chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "thứ .* chủ nhật , ngày \\d\\d\\d\\d?[/-]\\d\\d?[/-]\\d\\d\n",
      "sáng chủ nhật hàng tuần : \\d\\d?h\\d?\\d? - \\d\\d\\d?h\n",
      "\\d\\d?h , chủ nhật , ngày \\d tháng \\d .* \\d\\d\\d\\d\n",
      "sáng \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "sáng chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\)\n",
      "sáng chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "ngày \\d\\d tháng \\d\\d .* \\d\\d\\d\\d nhằm chủ nhật\n",
      "\\d\\d?h\\d?\\d? ngày \\d\\d?[/-]\\d\\d \\( chủ nhật \\)\n",
      "chủ nhật này \\( ngày \\d\\d - \\d\\d - \\d\\d\\d\\d \\)\n",
      "\\d\\d?h\\d?\\d? sáng ngày chủ nhật \\d.\\d.\\d\\d\\d\\d\n",
      "\\d\\d?h\\d?\\d? ngày chủ nhật \\( \\d\\d?[/-]\\d\\d \\)\n",
      "chủ nhật , ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật vừa rồi ngày \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "chiều chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật \\( \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d? \\)\n",
      "\\d\\d\\d?h\\d?\\d? ngày \\d[/-]\\d \\( chủ nhật \\)\n",
      "sáng chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật ngày \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "ngày chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật tuần này \\( \\d\\d.\\d\\d.\\d\\d\\d\\d \\)\n",
      "\\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d? \\( chủ nhật \\)\n",
      "chủ nhật này ngày \\d\\d?[/-]\\d\\d lúc \\dg\n",
      "\\d\\d?h sáng chủ nhật ngày \\d\\d?[/-]\\d\\d\n",
      "chủ nhật ngày \\d[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật , ngày \\d tháng \\d .* \\d\\d\\d\\d\n",
      " : chủ nhật ngày \\d\\d tháng \\d\\d .* \\d\n",
      "chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\\d?\\d?\n",
      "\\d\\dg ngày chủ nhật \\( \\d\\d?[/-]\\d \\)\n",
      "\\d\\dg chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\n",
      "\\d\\d : \\d\\d chủ nhật ngày \\d\\d?[/-]\\d\n",
      "\\d\\d?h sáng \\d[/-]\\d\\d \\( chủ nhật \\)\n",
      "\\d\\d\\d?h ngày \\d[/-]\\d \\( chủ nhật \\)\n",
      "\\d\\d\\d?h\\d?\\d? buổi tối ngày chủ nhật\n",
      "ngày chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\n",
      "\\d\\d?h\\d?\\d? sáng chủ nhật hàng tuần\n",
      "ngày chủ nhật \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "buổi sáng chủ nhật \\( \\d\\d?[/-]\\d \\)\n",
      "chủ nhật , \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật này \\d[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "chủ nhật \\d\\d?[/-]\\d[/-]\\d\\d\\d?\\d?\n",
      "ngày \\d\\d?[/-]\\d\\d \\( chủ nhật \\)\n",
      "ngày chủ nhật \\d\\d?[/-]\\d[/-]\\d\\d\n",
      "\\d\\d\\d?h\\d?\\d? chủ nhật tuần này\n",
      "chủ nhật này \\( \\d\\d?[/-]\\d\\d \\)\n",
      "tối chủ nhật ngày \\d\\d?[/-]\\d\\d\n",
      "chủ nhật \\d\\d?[/-]\\d\\d?[/-]\\d\\d\n",
      "\\d\\d\\d?h chủ nhật ngày \\d[/-]\\d\n",
      "sáng chủ nhật \\( \\d\\d?[/-]\\d \\)\n",
      "chủ nhật \\d\\d?[/-]\\d[/-]\\d\\d\n",
      "sáng chủ nhật \\d\\d?[/-]\\d\\d\n",
      "chủ nhật lúc \\d\\d\\d?h\\d?\\d?\n",
      "ngày chủ nhật \\d\\d?[/-]\\d\n",
      "chủ nhật \\( \\d[/-]\\d \\)\n",
      "chiều chủ nhật \\d[/-]\\d\n",
      "chủ nhật \\d\\d?[/-]\\d\\d\n",
      "thứ \\d và chủ nhật \\)\n",
      "chìu chủ nhật \\d\\d?h\n",
      "chủ nhật \\d\\d - \\d\n",
      "chủ nhật \\d[/-]\\d\n"
     ]
    }
   ],
   "source": [
    "with open('list_constants.json','r') as constant_file:\n",
    "    constant = json.load(constant_file)\n",
    "    list_pattern_time = constant['list_pattern_time']\n",
    "    res = []\n",
    "    for pattern in list_pattern_time:\n",
    "        if \"chủ nhật\" not in pattern:\n",
    "            res.append(pattern)\n",
    "            \n",
    "    constant['list_pattern_time'] = res\n",
    "    with open('list_constants_new.json', 'w+') as new_constant_file:\n",
    "        json.dump(constant,new_constant_file,ensure_ascii=False)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DuongCao",
   "language": "python",
   "name": "duongcao2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
